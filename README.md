# ğŸ¤– AutomatizaciÃ³n de Pruebas con JMeter

Repositorio para pruebas de performance y carga de endpoints HTTP usando Apache JMeter, con automatizaciÃ³n completa de ejecuciÃ³n, generaciÃ³n de reportes interactivos y soporte para integraciÃ³n continua (CI/CD).

## ğŸ“‹ DescripciÃ³n

Este proyecto automatiza pruebas de carga sobre endpoints HTTP utilizando JMeter 5.6.3, facilitando la ejecuciÃ³n local o en pipelines de CI/CD. Incluye scripts Python para orquestar las pruebas, validar configuraciones, generar reportes HTML interactivos y publicar resultados automÃ¡ticamente.

![JMeter Tests](https://github.com/dmelchor24/endpoints-jmeter-tests/actions/workflows/jmeter-tests.yaml/badge.svg)

ğŸ“Š **Reporte de la Ãºltima ejecuciÃ³n (GitHub Pages)**

ğŸ‘‰ https://dmelchor24.github.io/endpoints-jmeter-tests

### CaracterÃ­sticas principales

âœ… **AutomatizaciÃ³n completa** - EjecuciÃ³n y reportes en un solo comando  
âœ… **ParametrizaciÃ³n dinÃ¡mica** - Datos de prueba desde archivos CSV  
âœ… **Carga controlada** - Rampa gradual de usuarios concurrentes  
âœ… **Validaciones integradas** - Assertions de cÃ³digo HTTP y tiempos de respuesta  
âœ… **Reportes interactivos** - HTML con grÃ¡ficos y estadÃ­sticas detalladas  
âœ… **GitHub Pages ready** - PublicaciÃ³n automÃ¡tica de reportes  
âœ… **Docker-ready** - Ejecutable en cualquier entorno  
âœ… **HistÃ³rico completo** - Mantiene todas las ejecuciones anteriores  

## ğŸ“ Estructura del proyecto

```
â”œâ”€â”€ Dockerfile                          # Imagen Docker con JMeter 5.6.3 y Python 3
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ execute-tests.py                # Script principal de automatizaciÃ³n
â”œâ”€â”€ test-plans/jmeter/
â”‚   â””â”€â”€ tp-carga-controlada.jmx         # Plan de pruebas JMeter
â”œâ”€â”€ data/csv/
â”‚   â””â”€â”€ set-datos-creacion.csv          # 1000 registros de datos de prueba
â”œâ”€â”€ docs/                               # Reportes para GitHub Pages
â”‚   â”œâ”€â”€ index.html                      # RedirecciÃ³n al Ãºltimo reporte
â”‚   â””â”€â”€ report/                         # Reporte HTML mÃ¡s reciente
â”œâ”€â”€ results/                            # HistÃ³rico de ejecuciones
â”‚   â””â”€â”€ run_[timestamp]/
â”‚       â”œâ”€â”€ results_[timestamp].csv     # Datos de cada request
â”‚       â”œâ”€â”€ jmeter_[timestamp].log      # Log de ejecuciÃ³n
â”‚       â”œâ”€â”€ report_[timestamp]/         # Reporte HTML completo
â”‚       â””â”€â”€ statistics.json             # EstadÃ­sticas en JSON
â”œâ”€â”€ eventos/
â”‚   â””â”€â”€ curl.txt                        # Ejemplo de request curl
â””â”€â”€ README.md
```

## ğŸ”§ Requisitos

- **Python 3.x**
- **Apache JMeter 5.6.3 o superior** (instalado localmente o vÃ­a Docker)
- **Docker** (opcional, para ejecuciÃ³n en contenedores)

## ğŸš€ Uso rÃ¡pido

### 1. EjecuciÃ³n local

Instala JMeter y asegÃºrate de que estÃ© en tu PATH o define la variable de entorno `JMETER_HOME`.

```bash
python scripts/execute-tests.py --base-url=https://api.example.com --test-plan=test-plans/jmeter/tp-carga-controlada.jmx
```

**El script automÃ¡ticamente:**
- Valida y normaliza la URL proporcionada
- Busca JMeter en mÃºltiples ubicaciones
- Ejecuta el plan de pruebas
- Genera resultados en `results/run_[timestamp]/`
- Crea reporte HTML interactivo
- Copia el reporte a `docs/` para publicaciÃ³n
- Actualiza `docs/index.html` con redirecciÃ³n al Ãºltimo reporte

### 2. EjecuciÃ³n con Docker

Construye la imagen y ejecuta las pruebas en un contenedor:

```bash
# Construir imagen
docker build -t jmeter-tests .

# Ejecutar pruebas (Windows)
docker run --rm -v %cd%:/workspace -w /workspace jmeter-tests python3 scripts/execute-tests.py --base-url=https://api.example.com

# Ejecutar pruebas (Linux/Mac)
docker run --rm -v $(pwd):/workspace -w /workspace jmeter-tests python3 scripts/execute-tests.py --base-url=https://api.example.com
```

### 3. ParÃ¡metros y configuraciÃ³n

**Argumentos de lÃ­nea de comandos:**
- `--base-url`: URL base del endpoint a probar (requerido)
- `--test-plan`: Ruta al archivo JMX de JMeter (opcional, por defecto: `test-plans/jmeter/tp-carga-controlada.jmx`)

**Variables de entorno:**
- `BASE_URL`: URL base del endpoint (alternativa a `--base-url`)
- `TEST_PLAN`: Ruta al plan de pruebas (alternativa a `--test-plan`)

**Prioridad:** Argumentos CLI > Variables de entorno > Valores por defecto

**Ejemplo con variables de entorno:**
```bash
export BASE_URL=https://api.example.com
export TEST_PLAN=test-plans/jmeter/tp-carga-controlada.jmx
python scripts/execute-tests.py
```

## ğŸ“Š Plan de pruebas

El plan de pruebas `tp-carga-controlada.jmx` estÃ¡ configurado con:

### ConfiguraciÃ³n HTTP
- **Protocolo:** HTTPS
- **Host por defecto:** `endpoints-fast-api.onrender.com`
- **Timeout de conexiÃ³n:** 10 segundos
- **Timeout de respuesta:** 10 segundos

### Grupo de threads (Concurrency Thread Group)
- **Usuarios concurrentes:** 20
- **Rampa:** 2 minutos
- **Pasos:** 10
- **DuraciÃ³n:** 1 minuto

### Request HTTP
- **MÃ©todo:** POST
- **Endpoint:** `/api/v1/tasks/`
- **Body:** JSON con `title` y `description` (parametrizados desde CSV)
- **Headers:** `Content-Type: application/json`

### Validaciones
- **CÃ³digos de respuesta esperados:** 200 o 201
- **DuraciÃ³n mÃ¡xima por request:** 3 segundos
- **Timer uniforme:** 200-1000ms entre requests

### Datos de prueba
El archivo `data/csv/set-datos-creacion.csv` contiene 1000 registros con formato:
```csv
title;description
Tarea 1;DescripciÃ³n Tarea 1
Tarea 2;DescripciÃ³n Tarea 2
...
```

## ğŸ¨ Reportes generados

Cada ejecuciÃ³n genera:

1. **CSV de resultados** (`results_[timestamp].csv`)
   - Datos de cada request: timestamp, elapsed time, response code, latency, bytes, etc.

2. **Log de JMeter** (`jmeter_[timestamp].log`)
   - Log detallado de la ejecuciÃ³n

3. **Reporte HTML interactivo** (`report_[timestamp]/`)
   - Dashboard con grÃ¡ficos
   - EstadÃ­sticas de rendimiento
   - Tiempos de respuesta
   - Throughput
   - Percentiles

4. **EstadÃ­sticas JSON** (`statistics.json`)
   - Metadata de la ejecuciÃ³n
   - Timestamp, URL, cantidad de requests

## ğŸ”„ Flujo de ejecuciÃ³n

1. Usuario ejecuta `execute-tests.py` con URL base
2. Script valida URL y extrae host (sin protocolo)
3. Busca JMeter en mÃºltiples ubicaciones
4. Valida que el CSV de datos tenga registros
5. Ejecuta JMeter con parÃ¡metros dinÃ¡micos
6. Genera CSV con resultados de cada request
7. Genera reporte HTML con grÃ¡ficos y estadÃ­sticas
8. Copia reporte a `docs/` para GitHub Pages
9. Crea archivo de redirecciÃ³n y metadata
10. Muestra resumen: cantidad de requests, URL, timestamp

## ğŸ³ Dockerfile

La imagen Docker incluye:
- **Base:** Eclipse Temurin 11 JRE
- **JMeter:** 5.6.3
- **Python:** 3.x
- **Plugins:** Concurrency Thread Group (jmeter-plugins-casutg)
- **Zona horaria:** America/Guatemala
- **Health check:** Verifica instalaciÃ³n de JMeter

## ğŸ› ï¸ PersonalizaciÃ³n

### Modificar el plan de pruebas

Edita `test-plans/jmeter/tp-carga-controlada.jmx` para ajustar:
- NÃºmero de usuarios concurrentes
- DuraciÃ³n de la prueba
- Endpoints a probar
- Validaciones y assertions
- Timers y delays

### Agregar datos de prueba

Modifica `data/csv/set-datos-creacion.csv` con tus propios datos. Formato:
```csv
title;description
Tu tÃ­tulo;Tu descripciÃ³n
```

### Crear nuevos planes de prueba

1. Crea un nuevo archivo `.jmx` en `test-plans/jmeter/`
2. Configura el CSV Data Set Config apuntando a `/tests/data/csv/tu-archivo.csv`
3. Usa `${__P(base_url)}` para el dominio en HTTP Request Defaults
4. Ejecuta con `--test-plan=test-plans/jmeter/tu-plan.jmx`

## ğŸ“¤ PublicaciÃ³n de reportes

El reporte HTML mÃ¡s reciente se encuentra en `docs/report/index.html`. El archivo `docs/index.html` redirige automÃ¡ticamente al Ãºltimo reporte generado.

### Publicar en GitHub Pages

1. Ve a Settings > Pages en tu repositorio
2. Selecciona la rama `main` y carpeta `/docs`
3. Guarda los cambios
4. Los reportes estarÃ¡n disponibles en `https://tu-usuario.github.io/tu-repo/`

## ğŸ“ Validaciones del script

El script `execute-tests.py` incluye validaciones robustas:

- âœ… Valida formato de URL (rechaza markdown, espacios, esquemas invÃ¡lidos)
- âœ… Extrae host sin protocolo para JMeter
- âœ… Busca JMeter en mÃºltiples ubicaciones
- âœ… Verifica que el CSV tenga datos reales
- âœ… Maneja errores con mensajes descriptivos en colores
- âœ… Genera timestamps Ãºnicos para cada ejecuciÃ³n

## ğŸ“ˆ HistÃ³rico de ejecuciones

Todas las ejecuciones se guardan en `results/` con estructura:
```
results/
â”œâ”€â”€ run_20260215_222654/
â”œâ”€â”€ run_20260215_230931/
â”œâ”€â”€ run_20260215_231043/
â”œâ”€â”€ run_20260215_231741/
â””â”€â”€ run_20260215_232607/
```

Cada carpeta contiene los resultados completos de esa ejecuciÃ³n.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Haz fork del repositorio
2. Crea una rama para tu feature
3. Haz commit de tus cambios
4. Haz push a la rama
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ disponible bajo la licencia que especifiques.