name: Run JMeter Performance Tests

on:
  repository_dispatch:
    types: [run-jmeter-tests]

  workflow_dispatch:
    inputs:
      base_url:
        description: 'URL base de la API a probar'

        required: true
        default: 'http://localhost:8000'
        type: string
      test_plan:
        description: 'Ruta de Test plan a ejecutar'
        required: false
        default: 'test-plans/jmeter/tp-carga-controlada.jmx'
        type: string

permissions:
  contents: write

env:
  PYTHON_VERSION: '3.11'
  JMETER_VERSION: '5.6.3'

jobs:
  run-performance-tests:
    name: Ejecutar Pruebas de Performance con Docker
    runs-on: ubuntu-latest
    
    steps:
      # ============================================================
      # 1. CHECKOUT DEL C√ìDIGO
      - name: üì• Checkout c√≥digo
        uses: actions/checkout@v4
      
      # 2. CONFIGURAR DOCKER BUILDX
      - name: üê≥ Configurar Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      # 3. CONFIGURAR VARIABLES DE ENTORNO
      - name: ‚öôÔ∏è Configurar variables de entorno
        id: config
        run: |
          # Variables del test (prioridad: workflow_dispatch > repository_dispatch > default)
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            BASE_URL="${{ inputs.base_url }}"
            TEST_PLAN="${{ inputs.test_plan }}"
          elif [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            BASE_URL="${{ github.event.client_payload.base_url || 'http://localhost:8000' }}"
            TEST_PLAN="${{ github.event.client_payload.test_plan || 'test-plans/jmeter/tp-carga-controlada.jmx' }}"
          else
            BASE_URL="http://localhost:8000"
            TEST_PLAN="test-plans/jmeter/tp-carga-controlada.jmx"
          fi
          
          echo "base_url=$BASE_URL" >> $GITHUB_OUTPUT
          echo "test_plan=$TEST_PLAN" >> $GITHUB_OUTPUT
          
          echo "BASE_URL=$BASE_URL" >> $GITHUB_ENV
          echo "TEST_PLAN=$TEST_PLAN" >> $GITHUB_ENV
      
      # 4. MOSTRAR CONFIGURACI√ìN
      - name: üìã Mostrar configuraci√≥n del test
        run: |
          echo "================================================"
          echo "  CONFIGURACI√ìN DE LA PRUEBA"
          echo "================================================"
          echo "Base URL:    ${{ steps.config.outputs.base_url }}"
          echo "Test Plan:   ${{ steps.config.outputs.test_plan }}"
          echo "JMeter:      ${JMETER_VERSION}"
          echo "Python:      ${{ env.PYTHON_VERSION }}"
          echo "Runner:      Docker"
          echo "================================================"
      
      # 5. CACHE DE DOCKER LAYERS
      - name: üíæ Cache de Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-
      
      # 6. BUILD DE LA IMAGEN DOCKER
      - name: üî® Build imagen Docker de JMeter
        run: |
          echo "üî® Construyendo imagen Docker..."
            docker build \
              --build-arg JMETER_VERSION=${JMETER_VERSION} \
              -t jmeter-runner:latest \
              -f Dockerfile \
              .
          
          echo "‚úÖ Imagen construida exitosamente"
          docker images | grep jmeter-runner
          
            # Cache step removido por incompatibilidad con el driver Docker en GitHub Actions
      
      # 7. VALIDAR API (si es necesario)
      - name: üîç Validar que la API est√© disponible
        if: ${{ !contains(steps.config.outputs.base_url, 'localhost') }}
        run: |
          echo "üîç Verificando disponibilidad de: ${{ steps.config.outputs.base_url }}"
          
          MAX_RETRIES=5
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if curl -sf "${{ steps.config.outputs.base_url }}/health" > /dev/null 2>&1 || \
               curl -sf "${{ steps.config.outputs.base_url }}" > /dev/null 2>&1; then
              echo "‚úÖ API disponible"
              exit 0
            fi
            
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "‚ö†Ô∏è  Intento $RETRY_COUNT/$MAX_RETRIES - API no disponible, esperando..."
            sleep 10
          done
          
          echo "‚ùå API no disponible despu√©s de $MAX_RETRIES intentos"
          echo "‚ö†Ô∏è  Continuando de todas formas..."
      
      # 8. CREAR DIRECTORIOS PARA RESULTADOS
      - name: üìÇ Crear directorios
        run: |
          mkdir -p results
          mkdir -p docs
          chmod 777 results docs
      
      # 9. EJECUTAR PRUEBAS CON DOCKER
      - name: üöÄ Ejecutar pruebas de JMeter en Docker
        run: |
          echo "üê≥ Ejecutando contenedor Docker..."
          
          docker run --rm \
            -v $(pwd)/results:/tests/results \
            -v $(pwd)/docs:/tests/docs \
            -v $(pwd)/test-plans:/tests/test-plans:ro \
            -v $(pwd)/data:/tests/data:ro \
            -e BASE_URL="${{ steps.config.outputs.base_url }}" \
            -e TEST_PLAN="${{ steps.config.outputs.test_plan }}" \
            jmeter-runner:latest \
            python3 scripts/execute-tests.py \
              --base-url="${{ steps.config.outputs.base_url }}" \
              --test-plan="${{ steps.config.outputs.test_plan }}"
          
          echo "‚úÖ Pruebas completadas"
      
      # 10. VERIFICAR RESULTADOS GENERADOS
      - name: üîç Verificar resultados generados
        run: |
          echo "üìÇ Verificando estructura de archivos generados..."
          
          if [ -d "results" ]; then
            echo "‚úÖ Directorio results/ existe"
            ls -lah results/
          else
            echo "‚ùå No se encontr√≥ directorio results/"
            exit 1
          fi
          
          if [ -d "docs" ]; then
            echo "‚úÖ Directorio docs/ existe"
            ls -lah docs/
          else
            echo "‚ùå No se encontr√≥ directorio docs/"
            exit 1
          fi
          
          # Verificar que se gener√≥ el reporte
          if [ -f "docs/index.html" ]; then
            echo "‚úÖ Reporte HTML generado"
          else
            echo "‚ùå No se gener√≥ el reporte HTML"
            exit 1
          fi
      
      # 11. PUBLICAR RESULTADOS
      - name: üìä Publicar reporte HTML
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: jmeter-report-${{ github.run_number }}
          path: |
            docs/
            results/run_*/
          retention-days: 30
      
      # 12. GUARDAR RESULTADOS EN MAIN
      - name: üíæ Commit resultados en main/docs
        if: success()
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git checkout main
          git add docs/
          git commit -m "Add JMeter report - Run ${{ github.run_number }}" || echo "No changes to commit"
          git push origin main
      
      # 13. ANALIZAR RESULTADOS
      - name: üìà Analizar resultados
        if: success()
        run: |
          echo "üìä Analizando resultados..."
          
          # Buscar el archivo statistics.json m√°s reciente
          STATS_FILE=$(find results -name "statistics.json" -type f -printf '%T@ %p\n' 2>/dev/null | sort -n | tail -1 | cut -f2- -d" ")
          
          if [ -z "$STATS_FILE" ] || [ ! -f "$STATS_FILE" ]; then
            echo "‚ö†Ô∏è  No se encontr√≥ archivo de estad√≠sticas"
            echo "‚ÑπÔ∏è  El test se ejecut√≥ pero no hay datos para analizar"
            exit 0
          fi
          
          echo "üìÑ Archivo de estad√≠sticas: $STATS_FILE"
          
          # Extraer m√©tricas usando Python
          python3 << EOF
          import json
          import sys
          
          with open("$STATS_FILE", "r") as f:
              stats = json.load(f)
          
          total = stats.get("Total", {})
          error_pct = total.get("errorPct", 0)
          mean_time = total.get("meanResTime", 0)
          p95_time = total.get("pct2ResTime", 0)
          sample_count = total.get("sampleCount", 0)
          
          print(f"\n{'='*60}")
          print(f"  RESULTADOS DE LA PRUEBA")
          print(f"{'='*60}")
          print(f"Total peticiones:   {sample_count:,}")
          print(f"Tasa de error:      {error_pct:.2f}%")
          print(f"Tiempo promedio:    {mean_time:.2f}ms")
          print(f"Percentil 95:       {p95_time:.2f}ms")
          print(f"{'='*60}\n")
          
          # Definir umbrales
          ERROR_THRESHOLD = 5.0  # 5% de errores m√°ximo
          P95_THRESHOLD = 2000   # 2000ms m√°ximo para P95
          
          failed = False
          
          if error_pct > ERROR_THRESHOLD:
              print(f"‚ùå FALLO: Tasa de error ({error_pct:.2f}%) supera el umbral ({ERROR_THRESHOLD}%)")
              failed = True
          
          if p95_time > P95_THRESHOLD:
              print(f"‚ùå FALLO: P95 ({p95_time:.2f}ms) supera el umbral ({P95_THRESHOLD}ms)")
              failed = True
          
          if not failed:
              print("‚úÖ √âXITO: Todos los umbrales fueron cumplidos")
          
          # Guardar m√©tricas para el siguiente step
          with open("metrics.txt", "w") as f:
              f.write(f"error_pct={error_pct}\n")
              f.write(f"mean_time={mean_time}\n")
              f.write(f"p95_time={p95_time}\n")
              f.write(f"sample_count={sample_count}\n")
              f.write(f"failed={failed}\n")
          
          sys.exit(1 if failed else 0)
          EOF
      
      # 14. GUARDAR M√âTRICAS COMO OUTPUT
      - name: üíæ Guardar m√©tricas
        if: success() || failure()
        id: metrics
        run: |
          if [ -f "metrics.txt" ]; then
            cat metrics.txt >> $GITHUB_OUTPUT
          fi
      
      # 16. LIMPIAR CONTENEDORES E IM√ÅGENES
      - name: üßπ Limpiar Docker
        if: always()
        run: |
          echo "üßπ Limpiando recursos de Docker..."
          docker system prune -f
          echo "‚úÖ Limpieza completada"
      
      # 17. NOTIFICAR RESULTADO
      - name: üìß Notificar resultado
        if: always()
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "‚úÖ Las pruebas de performance completaron exitosamente"
          else
            echo "‚ùå Las pruebas de performance fallaron"
            echo "üìä Revisa los artefactos para m√°s detalles"
          fi
          echo "üîó URL del workflow: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"